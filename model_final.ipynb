{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aef533a8",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fb8106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import sem\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from keras.initializers import HeNormal\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ec3821",
   "metadata": {},
   "source": [
    "# Connect to SQLite Database and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459bbb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Games Table:\n",
      "  GameID MatchID     Map  Team1ID  Team2ID                Team1     Team2  \\\n",
      "0  60894   62393  Breeze     6903     6020  Booster Seat Gaming  Pho Real   \n",
      "1  60895   62393    Bind     6903     6020  Booster Seat Gaming  Pho Real   \n",
      "2  60896   62393   Haven     6903     6020  Booster Seat Gaming  Pho Real   \n",
      "3  60924   62403  Icebox     7046     7047       Bjor's Kittens  Mugiwara   \n",
      "4  60925   62403   Haven     7046     7047       Bjor's Kittens  Mugiwara   \n",
      "\n",
      "                Winner  Team1_TotalRounds  Team2_TotalRounds  ...  \\\n",
      "0  Booster Seat Gaming                 13                  7  ...   \n",
      "1             Pho Real                  2                 13  ...   \n",
      "2  Booster Seat Gaming                 13                  8  ...   \n",
      "3       Bjor's Kittens                 13                  6  ...   \n",
      "4       Bjor's Kittens                 13                  9  ...   \n",
      "\n",
      "  Team1_FullBuyWon Team2_PistolWon  Team2_Eco  Team2_EcoWon  Team2_SemiEco  \\\n",
      "0              8.0             0.0        4.0           0.0            2.0   \n",
      "1              1.0             2.0        2.0           2.0            0.0   \n",
      "2              9.0             1.0        2.0           1.0            2.0   \n",
      "3              8.0             0.0        4.0           0.0            1.0   \n",
      "4             11.0             1.0        3.0           2.0            3.0   \n",
      "\n",
      "   Team2_SemiEcoWon  Team2_SemiBuy  Team2_SemiBuyWon  Team2_FullBuy  \\\n",
      "0               0.0            4.0               1.0           10.0   \n",
      "1               0.0            4.0               3.0            9.0   \n",
      "2               0.0            6.0               2.0           11.0   \n",
      "3               0.0            2.0               1.0           12.0   \n",
      "4               0.0            4.0               3.0           12.0   \n",
      "\n",
      "   Team2_FullBuyWon  \n",
      "0               6.0  \n",
      "1               8.0  \n",
      "2               5.0  \n",
      "3               5.0  \n",
      "4               4.0  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "\n",
      "Game_Scoreboard Table:\n",
      "  GameID PlayerID PlayerName TeamAbbreviation    Agent    ACS  Kills  Deaths  \\\n",
      "0  60894     8419     Reduxx             Boos     jett  313.0   24.0    10.0   \n",
      "1  60894      466     ChurmZ             Boos  chamber  227.0   16.0    10.0   \n",
      "2  60894     3712   diaamond             Boos     sova  226.0   17.0     9.0   \n",
      "3  60894     5099     Boltzy             Boos    viper  218.0   17.0    12.0   \n",
      "4  60894     3983     Virtyy             Boos     skye   80.0    5.0    13.0   \n",
      "\n",
      "   Assists  PlusMinus  ...  Num_4Ks  Num_5Ks  OnevOne  OnevTwo  OnevThree  \\\n",
      "0      3.0       14.0  ...      2.0      0.0      1.0      0.0        0.0   \n",
      "1      7.0        6.0  ...      0.0      0.0      0.0      0.0        0.0   \n",
      "2      8.0        8.0  ...      0.0      0.0      1.0      0.0        0.0   \n",
      "3      2.0        5.0  ...      0.0      0.0      1.0      0.0        0.0   \n",
      "4      3.0       -8.0  ...      0.0      0.0      0.0      0.0        0.0   \n",
      "\n",
      "   OnevFour  OnevFive  Econ  Plants  Defuses  \n",
      "0       0.0       0.0  74.0     0.0      0.0  \n",
      "1       0.0       0.0  67.0     2.0      0.0  \n",
      "2       0.0       0.0  58.0     3.0      0.0  \n",
      "3       0.0       0.0  48.0     0.0      0.0  \n",
      "4       0.0       0.0  21.0     0.0      0.0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Connect to SQLite database and load data into pandas DataFrame\n",
    "conn = sqlite3.connect('valorant.sqlite')\n",
    "\n",
    "# Load data from the 'Games' and 'Game_Scoreboard' tables\n",
    "query_games = \"SELECT * FROM Games\"\n",
    "query_scoreboard = \"SELECT * FROM Game_Scoreboard\"\n",
    "df_games = pd.read_sql_query(query_games, conn)\n",
    "df_scoreboard = pd.read_sql_query(query_scoreboard, conn)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Display the first few rows of both datasets\n",
    "print(\"Games Table:\")\n",
    "print(df_games.head())\n",
    "print(\"\\nGame_Scoreboard Table:\")\n",
    "print(df_scoreboard.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b300ec9",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1471b0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and Merged Data:\n",
      "  GameID MatchID     Map  Team1ID  Team2ID                Team1     Team2  \\\n",
      "0  60894   62393  Breeze     6903     6020  Booster Seat Gaming  Pho Real   \n",
      "1  60894   62393  Breeze     6903     6020  Booster Seat Gaming  Pho Real   \n",
      "2  60894   62393  Breeze     6903     6020  Booster Seat Gaming  Pho Real   \n",
      "3  60894   62393  Breeze     6903     6020  Booster Seat Gaming  Pho Real   \n",
      "4  60894   62393  Breeze     6903     6020  Booster Seat Gaming  Pho Real   \n",
      "\n",
      "   Winner  Team1_TotalRounds  Team2_TotalRounds  ... Num_4Ks Num_5Ks  OnevOne  \\\n",
      "0       1                 13                  7  ...     2.0     0.0      1.0   \n",
      "1       1                 13                  7  ...     0.0     0.0      0.0   \n",
      "2       1                 13                  7  ...     0.0     0.0      1.0   \n",
      "3       1                 13                  7  ...     0.0     0.0      1.0   \n",
      "4       1                 13                  7  ...     0.0     0.0      0.0   \n",
      "\n",
      "   OnevTwo  OnevThree  OnevFour  OnevFive  Econ  Plants  Defuses  \n",
      "0      0.0        0.0       0.0       0.0  74.0     0.0      0.0  \n",
      "1      0.0        0.0       0.0       0.0  67.0     2.0      0.0  \n",
      "2      0.0        0.0       0.0       0.0  58.0     3.0      0.0  \n",
      "3      0.0        0.0       0.0       0.0  48.0     0.0      0.0  \n",
      "4      0.0        0.0       0.0       0.0  21.0     0.0      0.0  \n",
      "\n",
      "[5 rows x 63 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\AppData\\Local\\Temp\\ipykernel_26172\\626654655.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['Winner'] = df_cleaned['Winner'].apply(lambda x: 1 if x == df_cleaned['Team1'].iloc[0] else 0)\n"
     ]
    }
   ],
   "source": [
    "# Clean the data by removing rows with missing values\n",
    "df_cleaned = df_games.dropna()\n",
    "\n",
    "# Convert the 'Winner' column to binary (1 for Team1 win, 0 for Team2 win)\n",
    "df_cleaned['Winner'] = df_cleaned['Winner'].apply(lambda x: 1 if x == df_cleaned['Team1'].iloc[0] else 0)\n",
    "\n",
    "# Merge the cleaned Games table with the Game_Scoreboard table\n",
    "df_cleaned = df_cleaned.merge(df_scoreboard, on='GameID')\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"Cleaned and Merged Data:\")\n",
    "print(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e47448",
   "metadata": {},
   "source": [
    "# Feature Selection and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f72c924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix (X):\n",
      "     ACS  Kills  Deaths  Assists  PlusMinus  KAST_Percent    ADR  HS_Percent  \\\n",
      "0  313.0   24.0    10.0      3.0       14.0          0.65  195.0        0.31   \n",
      "1  227.0   16.0    10.0      7.0        6.0          0.90  161.0        0.16   \n",
      "2  226.0   17.0     9.0      8.0        8.0          0.85  148.0        0.27   \n",
      "3  218.0   17.0    12.0      2.0        5.0          0.70  141.0        0.19   \n",
      "4   80.0    5.0    13.0      3.0       -8.0          0.70   55.0        0.22   \n",
      "\n",
      "   FirstKills  FirstDeaths  FKFD_PlusMinus  Num_2Ks  Num_3Ks  Num_4Ks  Num_5Ks  \n",
      "0         4.0          4.0             0.0      2.0      2.0      2.0      0.0  \n",
      "1         1.0          1.0             0.0      3.0      1.0      0.0      0.0  \n",
      "2         3.0          0.0             3.0      1.0      2.0      0.0      0.0  \n",
      "3         3.0          0.0             3.0      3.0      1.0      0.0      0.0  \n",
      "4         3.0          1.0             2.0      1.0      0.0      0.0      0.0  \n",
      "\n",
      "Target Variable (y):\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: Winner, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select relevant features for the model\n",
    "X = df_cleaned[['ACS', 'Kills', 'Deaths', 'Assists', 'PlusMinus', 'KAST_Percent', 'ADR', 'HS_Percent',\n",
    "                'FirstKills', 'FirstDeaths', 'FKFD_PlusMinus', 'Num_2Ks', 'Num_3Ks', 'Num_4Ks', 'Num_5Ks']]\n",
    "\n",
    "# The target variable is the 'Winner' column\n",
    "y = df_cleaned['Winner']\n",
    "\n",
    "# Display the selected features and the target variable\n",
    "print(\"Feature Matrix (X):\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget Variable (y):\")\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e113ce",
   "metadata": {},
   "source": [
    "# Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eda3d924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed Feature Matrix (X_imputed):\n",
      "[[ 2.98000000e+02  2.00000000e+01  1.10000000e+01  4.00000000e+00\n",
      "   9.00000000e+00  6.97199287e-01  1.91000000e+02  3.40000000e-01\n",
      "   6.00000000e+00  1.00000000e+00  5.00000000e+00  3.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00]\n",
      " [ 1.96000000e+02  1.40000000e+01  1.40000000e+01  2.00000000e+00\n",
      "   0.00000000e+00  6.97199287e-01  1.39000000e+02  1.40000000e-01\n",
      "   2.00000000e+00  3.00000000e+00 -1.00000000e+00  3.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 1.94000000e+02  1.50000000e+01  1.40000000e+01  4.00000000e+00\n",
      "   1.00000000e+00  6.97199287e-01  1.43000000e+02  2.80000000e-01\n",
      "   1.00000000e+00  2.00000000e+00 -1.00000000e+00  4.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 3.00000000e+02  2.40000000e+01  1.80000000e+01  1.00000000e+01\n",
      "   6.00000000e+00  6.97199287e-01  2.07000000e+02  2.20000000e-01\n",
      "   5.00000000e+00  3.00000000e+00  2.00000000e+00  5.00000000e+00\n",
      "   2.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 2.25000000e+02  2.00000000e+01  2.20000000e+01  6.00000000e+00\n",
      "  -2.00000000e+00  7.90000000e-01  1.48000000e+02  4.40000000e-01\n",
      "   8.00000000e+00  4.00000000e+00  4.00000000e+00  5.00000000e+00\n",
      "   1.00000000e+00  0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values with the mean of each column\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Shuffle the data\n",
    "X_imputed, y = shuffle(X_imputed, y, random_state=42)\n",
    "\n",
    "# Display the first few rows of the imputed feature matrix\n",
    "print(\"Imputed Feature Matrix (X_imputed):\")\n",
    "print(X_imputed[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f1671",
   "metadata": {},
   "source": [
    "# Standardize the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2090cf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Feature Matrix (X_processed):\n",
      "[[ 1.52073439e+00  1.00017938e+00 -9.03400618e-01 -3.89000817e-01\n",
      "   1.42414841e+00  2.99926918e-11  1.52023229e+00  1.15948736e+00\n",
      "   2.26139133e+00 -6.51672922e-01  2.33896814e+00  2.38833356e-01\n",
      "  -8.60774273e-01  1.98134166e+00 -1.42671856e-01]\n",
      " [-1.07815447e-01 -9.05643186e-02 -1.29824668e-01 -1.03512991e+00\n",
      "   8.37055596e-04  2.99926918e-11  2.09166270e-01 -1.04984261e+00\n",
      "  -3.04780593e-02  5.87653154e-01 -4.68656378e-01  2.38833356e-01\n",
      "   2.07755144e-01 -4.03843116e-01 -1.42671856e-01]\n",
      " [-1.39747797e-01  9.12262971e-02 -1.29824668e-01 -3.89000817e-01\n",
      "   1.58982761e-01  2.99926918e-11  3.10017502e-01  4.96688370e-01\n",
      "  -6.03445407e-01 -3.20098840e-02 -4.68656378e-01  8.38459426e-01\n",
      "   2.07755144e-01 -4.03843116e-01 -1.42671856e-01]\n",
      " [ 1.55266674e+00  1.72734184e+00  9.01609933e-01  1.54938646e+00\n",
      "   9.49711290e-01  2.99926918e-11  1.92363722e+00 -1.66110623e-01\n",
      "   1.68842399e+00  5.87653154e-01  9.35155881e-01  1.43808550e+00\n",
      "   1.27628456e+00 -4.03843116e-01 -1.42671856e-01]\n",
      " [ 3.55203624e-01  1.00017938e+00  1.93304453e+00  2.57128276e-01\n",
      "  -3.15454356e-01  4.60424732e+00  4.36081542e-01  2.26415235e+00\n",
      "   3.40732603e+00  1.20731619e+00  1.87103072e+00  1.43808550e+00\n",
      "   2.07755144e-01 -4.03843116e-01 -1.42671856e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features (mean=0, variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_processed = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Display the standardized feature matrix\n",
    "print(\"Standardized Feature Matrix (X_processed):\")\n",
    "print(X_processed[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582ccba0",
   "metadata": {},
   "source": [
    "# Define the DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e7e5af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,185</span> (51.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,185\u001b[0m (51.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> (50.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,801\u001b[0m (50.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Define the DNN model architecture\n",
    "def build_dnn_model(input_dim):\n",
    "    initializer = HeNormal()\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Dense(128, activation=\"elu\", kernel_initializer=initializer, input_shape=(input_dim,)),\n",
    "            Dropout(0.1),\n",
    "            BatchNormalization(),\n",
    "            Dense(64, activation=\"elu\", kernel_initializer=initializer),\n",
    "            Dropout(0.1),\n",
    "            BatchNormalization(),\n",
    "            Dense(32, activation=\"elu\", kernel_initializer=initializer),\n",
    "            Dense(1, activation=\"sigmoid\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Display the DNN model summary\n",
    "model = build_dnn_model(X_processed.shape[1])\n",
    "model.summary()\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a31552",
   "metadata": {},
   "source": [
    " # Evaluate the DNN Model using K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c42ceb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m924/924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m924/924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m924/924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m924/924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kusha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m924/924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step\n",
      "DNN Model Accuracy Scores: [99.92554739585096, 99.93231581440996, 99.91201055873296, 99.91539476801246, 99.94246649519425]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate DNN with K-Fold Cross-Validation\n",
    "def evaluate_with_kfold(X, y, model_builder, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "    accuracy_scores = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        x_train_fold, x_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "        model = model_builder(input_dim=X.shape[1])\n",
    "        model.fit(x_train_fold, y_train_fold, epochs=5, batch_size=512, verbose=0)\n",
    "\n",
    "        y_pred_fold = model.predict(x_test_fold)\n",
    "        y_pred_fold = np.round(y_pred_fold)\n",
    "        score = accuracy_score(y_test_fold, y_pred_fold)\n",
    "        accuracy_scores.append(score * 100)\n",
    "\n",
    "    return accuracy_scores\n",
    "\n",
    "# Evaluate the DNN model\n",
    "dnn_accuracy = evaluate_with_kfold(X_processed, y, build_dnn_model, n_splits=5)\n",
    "print(\"DNN Model Accuracy Scores:\", dnn_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1777c23",
   "metadata": {},
   "source": [
    "# Evaluate the Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c33daf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Model Accuracy Scores: [99.91539476801246, 99.91539476801246, 99.90185793089445, 99.90862634945346, 99.91200758088534]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Gradient Boosting Classifier\n",
    "def evaluate_gboost_with_kfold(X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "    accuracy_scores = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        x_train_fold, x_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "\n",
    "        gbc = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "        gbc.fit(x_train_fold, y_train_fold)\n",
    "\n",
    "        y_pred_fold = gbc.predict(x_test_fold)\n",
    "        score = accuracy_score(y_test_fold, y_pred_fold)\n",
    "        accuracy_scores.append(score * 100)\n",
    "\n",
    "    return accuracy_scores\n",
    "\n",
    "# Evaluate the Gradient Boosting model\n",
    "gboost_accuracy = evaluate_gboost_with_kfold(X_processed, y, n_splits=5)\n",
    "print(\"Gradient Boosting Model Accuracy Scores:\", gboost_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d94e09",
   "metadata": {},
   "source": [
    "# Print Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56101d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DNN Model:\n",
      "List of Accuracy Scores: [99.92554739585096, 99.93231581440996, 99.91201055873296, 99.91539476801246, 99.94246649519425]\n",
      "Maximum Accuracy: 99.94%\n",
      "Minimum Accuracy: 99.91%\n",
      "Overall Accuracy: 99.93%\n",
      "Standard Deviation: 0.01%\n",
      "Standard Error: 0.01%\n",
      "\n",
      "Gradient Boosting Model:\n",
      "List of Accuracy Scores: [99.91539476801246, 99.91539476801246, 99.90185793089445, 99.90862634945346, 99.91200758088534]\n",
      "Maximum Accuracy: 99.92%\n",
      "Minimum Accuracy: 99.90%\n",
      "Overall Accuracy: 99.91%\n",
      "Standard Deviation: 0.01%\n",
      "Standard Error: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Print model statistics (maximum, minimum, overall accuracy, etc.)\n",
    "def print_statistics(accuracy_scores, model_name):\n",
    "    print(f\"\\n{model_name} Model:\")\n",
    "    print(f\"List of Accuracy Scores: {accuracy_scores}\")\n",
    "    print(f\"Maximum Accuracy: {max(accuracy_scores):.2f}%\")\n",
    "    print(f\"Minimum Accuracy: {min(accuracy_scores):.2f}%\")\n",
    "    print(f\"Overall Accuracy: {np.mean(accuracy_scores):.2f}%\")\n",
    "    print(f\"Standard Deviation: {np.std(accuracy_scores):.2f}%\")\n",
    "    print(f\"Standard Error: {sem(accuracy_scores):.2f}%\")\n",
    "\n",
    "# Print DNN statistics\n",
    "print_statistics(dnn_accuracy, \"DNN\")\n",
    "\n",
    "# Print Gradient Boosting statistics\n",
    "print_statistics(gboost_accuracy, \"Gradient Boosting\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ae5a7",
   "metadata": {},
   "source": [
    "# Retrieve Player Stats for Each Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "271367bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team 1 Player IDs: ['3145', '2083', '8669', '14799', '19697']\n",
      "Team 2 Player IDs: ['8179', '2124', '450', '14991', '7119']\n",
      "Team 1 Stats:\n",
      "ACS               205.513514\n",
      "Kills              14.864865\n",
      "Deaths             14.702703\n",
      "Assists             5.810811\n",
      "PlusMinus           0.162162\n",
      "KAST_Percent             NaN\n",
      "ADR               137.055556\n",
      "HS_Percent          0.226944\n",
      "FirstKills          1.216216\n",
      "FirstDeaths         1.388889\n",
      "FKFD_PlusMinus     -0.194444\n",
      "Num_2Ks             3.083333\n",
      "Num_3Ks             0.555556\n",
      "Num_4Ks             0.222222\n",
      "Num_5Ks             0.027778\n",
      "dtype: float64\n",
      "\n",
      "Team 2 Stats:\n",
      "ACS               176.019608\n",
      "Kills              12.607843\n",
      "Deaths             13.745098\n",
      "Assists             5.686275\n",
      "PlusMinus          -1.137255\n",
      "KAST_Percent        0.605000\n",
      "ADR               124.634146\n",
      "HS_Percent          0.186750\n",
      "FirstKills          1.313725\n",
      "FirstDeaths         1.325000\n",
      "FKFD_PlusMinus     -0.125000\n",
      "Num_2Ks             2.200000\n",
      "Num_3Ks             0.700000\n",
      "Num_4Ks             0.125000\n",
      "Num_5Ks             0.025000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Function to retrieve and aggregate player stats for a given team based on player IDs\n",
    "def get_team_stats(player_ids, df_scoreboard):\n",
    "    # Filter the scoreboard for the given player IDs\n",
    "    team_stats = df_scoreboard[df_scoreboard['PlayerID'].isin(player_ids)]\n",
    "    \n",
    "    # Aggregate the statistics by averaging the player's stats (ACS, Kills, Deaths, etc.)\n",
    "    team_stats_mean = team_stats[['ACS', 'Kills', 'Deaths', 'Assists', 'PlusMinus', \n",
    "                                  'KAST_Percent', 'ADR', 'HS_Percent', 'FirstKills', \n",
    "                                  'FirstDeaths', 'FKFD_PlusMinus', 'Num_2Ks', \n",
    "                                  'Num_3Ks', 'Num_4Ks', 'Num_5Ks']].mean()\n",
    "    \n",
    "    return team_stats_mean\n",
    "\n",
    "# Assuming df_scoreboard is already loaded as a DataFrame\n",
    "# Retrieve unique player IDs from the scoreboard\n",
    "unique_player_ids = df_scoreboard['PlayerID'].unique()\n",
    "\n",
    "# Randomly select 5 player IDs for Team 1 and Team 2\n",
    "team1_player_ids = random.sample(list(unique_player_ids), 5)\n",
    "team2_player_ids = random.sample(list(set(unique_player_ids) - set(team1_player_ids)), 5)\n",
    "\n",
    "# Display the selected player IDs\n",
    "print(f\"Team 1 Player IDs: {team1_player_ids}\")\n",
    "print(f\"Team 2 Player IDs: {team2_player_ids}\")\n",
    "\n",
    "# Get stats for both teams using the randomly selected player IDs\n",
    "team1_stats = get_team_stats(team1_player_ids, df_scoreboard)\n",
    "team2_stats = get_team_stats(team2_player_ids, df_scoreboard)\n",
    "\n",
    "# Display the aggregated stats for both teams\n",
    "print(\"Team 1 Stats:\")\n",
    "print(team1_stats)\n",
    "print(\"\\nTeam 2 Stats:\")\n",
    "print(team2_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be9c05",
   "metadata": {},
   "source": [
    "# Prepare the Input for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d532e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match Feature Vector (Differences):\n",
      "[[ 2.94939057e+01  2.25702173e+00  9.57604663e-01  1.24536301e-01\n",
      "   1.29941706e+00             nan  1.24214092e+01  4.01944444e-02\n",
      "  -9.75092740e-02  6.38888889e-02 -6.94444444e-02  8.83333333e-01\n",
      "  -1.44444444e-01  9.72222222e-02  2.77777778e-03]]\n",
      "Match Feature Vector (Standardized):\n",
      "[[-2.76628087 -2.22532757 -3.49291913 -1.64102574  0.20633428         nan\n",
      "  -2.98223544 -2.15235964 -1.23228239 -1.23174638 -0.03321461 -1.03037516\n",
      "  -1.01511741 -0.17195015 -0.12335396]]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the statistics for both teams into a single feature vector\n",
    "match_features = pd.concat([team1_stats, team2_stats], axis=0)  # This still gives 30 features\n",
    "\n",
    "# Instead of using both team's stats, you can calculate differences or means\n",
    "# For example, let's create a feature vector based on the difference of means\n",
    "match_features = (team1_stats - team2_stats).values.reshape(1, -1)\n",
    "\n",
    "# Ensure match_features has the same length as the original model's input (15 features)\n",
    "print(\"Match Feature Vector (Differences):\")\n",
    "print(match_features)\n",
    "\n",
    "# Standardize the features using the same scaler used for training\n",
    "match_features_scaled = scaler.transform(match_features)\n",
    "\n",
    "# Display the final feature matrix\n",
    "print(\"Match Feature Vector (Standardized):\")\n",
    "print(match_features_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becf04ec",
   "metadata": {},
   "source": [
    "# Predict the Winner Using DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "624c7bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "DNN Prediction: Team 2 wins\n"
     ]
    }
   ],
   "source": [
    "# Predict the winner using the trained DNN model\n",
    "dnn_winner_prob = model.predict(match_features_scaled)\n",
    "dnn_winner = np.round(dnn_winner_prob).astype(int)\n",
    "\n",
    "# Print the DNN model's prediction\n",
    "print(f\"DNN Prediction: {'Team 1 wins' if dnn_winner == 1 else 'Team 2 wins'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5e13d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
